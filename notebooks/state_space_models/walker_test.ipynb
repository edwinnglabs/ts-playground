{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce5cbae-6cfd-404c-9d43-a335eb7cc8a6",
   "metadata": {},
   "source": [
    "This is purely experiemental by testing state space model ideas from [Vihola, Helske, Franks \\(2020\\)](https://onlinelibrary.wiley.com/doi/10.1111/sjos.12492). Stan source code can be found [here](https://github.com/helske/walker). Although the main idea for the article is on the importance sampling, which is not tested yet in this notebook, we still use the process to compare unsmoothed states estimation for study purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f77c45b8-5513-4c18-b48f-8a893978e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "multiprocessing.set_start_method(\"fork\", force=True)\n",
    "\n",
    "from orbit.utils.stan import get_compiled_stan_model_simplified, compile_stan_model_simplified\n",
    "from orbit.utils.dataset import load_iclaims\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "002cf360-8bb4-454b-b468-87abaf7036f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = load_iclaims()\n",
    "y = raw_data['claims']\n",
    "y = (y - np.mean(y))/np.std(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5645c41f-f6b6-46f0-ba7a-7092faa463f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fourier_series(n, period, order=3, shift=0):\n",
    "    t = np.arange(1, n + 1) + shift\n",
    "    out = list()\n",
    "    for i in range(1, order + 1):\n",
    "        x = 2.0 * i * np.pi * t / period\n",
    "        out.append(np.cos(x))\n",
    "        out.append(np.sin(x))\n",
    "    out = np.column_stack(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8b4337d3-9b47-4846-a476-ff943ed36b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept_reg = np.ones((len(y), 1))\n",
    "fs_reg = make_fourier_series(len(y), 52, order=3)\n",
    "xreg = np.concatenate([intercept_reg, fs_reg], -1)\n",
    "m = xreg.shape[1]\n",
    "a1 = np.array([y[1]] + [0.0] * (m-1))\n",
    "p1 = np.zeros_like(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec86fa-2f07-4a6f-9793-1211b18bb05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "walker_model_path = \"./stan/walker.stan\"\n",
    "compiled_path = compile_stan_model_simplified(walker_model_path)\n",
    "walker_mod = get_compiled_stan_model_simplified(compiled_path)\n",
    "del compiled_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3139164-8631-451c-bf01-dc9e32e26b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'n' : len(y),\n",
    "    'k' : 1,\n",
    "    'xreg' : xreg,\n",
    "    'y': y,\n",
    "    'beta_mean' : np.zeros((1)),\n",
    "    'beta_sd' : np.ones((1)),\n",
    "    'sigma_mean': np.ones((2, )),\n",
    "    'sigma_sd': np.ones((2, )),\n",
    "    'n_new': 0,\n",
    "    'xreg_new': np.ones((1, 0)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a18a9d3-a6ee-4890-8971-65f7e244e910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient evaluation took 0.001652 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 16.52 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      "Gradient evaluation took 0.001507 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 15.07 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      "Gradient evaluation took 0.001309 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 13.09 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      "Gradient evaluation took 0.001273 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 12.73 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:    1 / 5000 [  0%]  (Warmup)\n",
      "Iteration:    1 / 5000 [  0%]  (Warmup)\n",
      "Iteration:    1 / 5000 [  0%]  (Warmup)\n",
      "Iteration:    1 / 5000 [  0%]  (Warmup)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: Exception: multiply: A[1] is nan, but must not be nan!  (in 'unknown file name' at line 19)\n",
      "  (in 'unknown file name' at line 99)\n",
      "\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: Exception: multiply: A[1] is nan, but must not be nan!  (in 'unknown file name' at line 19)\n",
      "  (in 'unknown file name' at line 99)\n",
      "\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: Exception: multiply: A[1] is nan, but must not be nan!  (in 'unknown file name' at line 19)\n",
      "  (in 'unknown file name' at line 99)\n",
      "\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  500 / 5000 [ 10%]  (Warmup)\n",
      "Iteration:  500 / 5000 [ 10%]  (Warmup)\n",
      "Iteration:  500 / 5000 [ 10%]  (Warmup)\n",
      "Iteration:  500 / 5000 [ 10%]  (Warmup)\n",
      "Iteration: 1000 / 5000 [ 20%]  (Warmup)\n",
      "Iteration: 1000 / 5000 [ 20%]  (Warmup)\n",
      "Iteration: 1000 / 5000 [ 20%]  (Warmup)\n",
      "Iteration: 1000 / 5000 [ 20%]  (Warmup)\n",
      "Iteration: 1500 / 5000 [ 30%]  (Warmup)\n",
      "Iteration: 1500 / 5000 [ 30%]  (Warmup)\n",
      "Iteration: 1500 / 5000 [ 30%]  (Warmup)\n",
      "Iteration: 1500 / 5000 [ 30%]  (Warmup)\n",
      "Iteration: 2000 / 5000 [ 40%]  (Warmup)\n",
      "Iteration: 2000 / 5000 [ 40%]  (Warmup)\n",
      "Iteration: 2000 / 5000 [ 40%]  (Warmup)\n",
      "Iteration: 2000 / 5000 [ 40%]  (Warmup)\n",
      "Iteration: 2500 / 5000 [ 50%]  (Warmup)\n",
      "Iteration: 2500 / 5000 [ 50%]  (Warmup)\n",
      "Iteration: 2500 / 5000 [ 50%]  (Warmup)\n",
      "Iteration: 2500 / 5000 [ 50%]  (Warmup)\n",
      "Iteration: 3000 / 5000 [ 60%]  (Warmup)\n",
      "Iteration: 3000 / 5000 [ 60%]  (Warmup)\n",
      "Iteration: 3000 / 5000 [ 60%]  (Warmup)\n",
      "Iteration: 3000 / 5000 [ 60%]  (Warmup)\n",
      "Iteration: 3500 / 5000 [ 70%]  (Warmup)\n",
      "Iteration: 3500 / 5000 [ 70%]  (Warmup)\n",
      "Iteration: 3500 / 5000 [ 70%]  (Warmup)\n",
      "Iteration: 3500 / 5000 [ 70%]  (Warmup)\n",
      "Iteration: 4000 / 5000 [ 80%]  (Warmup)\n",
      "Iteration: 4001 / 5000 [ 80%]  (Sampling)\n",
      "Iteration: 4000 / 5000 [ 80%]  (Warmup)\n",
      "Iteration: 4001 / 5000 [ 80%]  (Sampling)\n",
      "Iteration: 4000 / 5000 [ 80%]  (Warmup)\n",
      "Iteration: 4001 / 5000 [ 80%]  (Sampling)\n",
      "Iteration: 4000 / 5000 [ 80%]  (Warmup)\n",
      "Iteration: 4001 / 5000 [ 80%]  (Sampling)\n",
      "Iteration: 4500 / 5000 [ 90%]  (Sampling)\n",
      "Iteration: 4500 / 5000 [ 90%]  (Sampling)\n",
      "Iteration: 4500 / 5000 [ 90%]  (Sampling)\n",
      "Iteration: 4500 / 5000 [ 90%]  (Sampling)\n",
      "Iteration: 5000 / 5000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 26.1665 seconds (Warm-up)\n",
      "               6.91263 seconds (Sampling)\n",
      "               33.0791 seconds (Total)\n",
      "\n",
      "Iteration: 5000 / 5000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 26.1839 seconds (Warm-up)\n",
      "               7.33183 seconds (Sampling)\n",
      "               33.5158 seconds (Total)\n",
      "\n",
      "Iteration: 5000 / 5000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 26.2717 seconds (Warm-up)\n",
      "               7.52385 seconds (Sampling)\n",
      "               33.7955 seconds (Total)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5000 / 5000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 26.4267 seconds (Warm-up)\n",
      "               7.66955 seconds (Sampling)\n",
      "               34.0962 seconds (Total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "walker_fit = walker_mod.sampling(\n",
    "    data=data,\n",
    "    warmup=4000,\n",
    "    iter=5000,\n",
    "    chains=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca2eb3-ac1b-4cbf-9dc7-ce1c85711b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "az_posteriors = az.from_pystan(walker_fit)\n",
    "# converging\n",
    "az.plot_trace(az_posteriors, var_names=['sigma_b', 'sigma_y'], compact=False, figsize=(24, 12));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef2361-7ea1-45e8-8a31-58411af301ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors = walker_fit.extract(permuted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a130f3a5-a2a6-4fff-8c29-6385ca7c33b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_mean = posteriors['y_rep']\n",
    "states_mean = np.mean(states_mean, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a2395b-86ec-4c64-9655-751f63bfe659",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "x = np.arange(0, len(y))\n",
    "ax.scatter(x, y, c='grey')\n",
    "ax.plot(x, states_mean, color='blue');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts-research",
   "language": "python",
   "name": "ts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
